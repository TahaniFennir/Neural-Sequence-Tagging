{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the data \n",
    "\n",
    "* Note the use of the %%bash command to issue a shell command in linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "w5nLz43LbKMT",
    "outputId": "d7526a81-4466-43df-f829-8ed2f275e745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A B\n",
      "group I\n",
      "of I\n",
      "5 I\n",
      "scuba I\n",
      "divers I\n",
      "talk O\n",
      "on O\n",
      "the B\n",
      "surface I\n",
      "next O\n",
      "to O\n",
      "a B\n",
      "barrier I\n",
      "island I\n",
      ". O\n",
      "\n",
      "Man B\n",
      "with O\n",
      "long B\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -20 f30kE-captions-bio.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecqfYZ4kbKMh"
   },
   "source": [
    "### Creating a list of lists of tokens (one list per sentence) and the corresponding lists of labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "1e-pzyiPbKMi",
    "outputId": "0c06c0eb-6db7-4e04-e2b4-0a8a9fcdab32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n",
      "['Man', 'with', 'long', 'blond-hair', 'and', 'a', 'plate', 'of', 'food', 'in', 'his', 'hands', '.']\n",
      "['B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']\n"
     ]
    }
   ],
   "source": [
    " # YOUR CODE HERE\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open('f30kE-captions-bio.txt') as fp:\n",
    "    text = []\n",
    "    label = []\n",
    "    for line in fp:\n",
    "        tokens = line.strip().split()\n",
    "        if len(tokens) == 0:\n",
    "            texts.append(text)\n",
    "            labels.append(label)\n",
    "            text = []\n",
    "            label = []\n",
    "        else:\n",
    "            text.append(tokens[0])\n",
    "            label.append(tokens[1])\n",
    "print(len(texts))\n",
    "\n",
    "print(texts[1])\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuckS_TsbKMy"
   },
   "source": [
    "### Mapping labels to integers and sequence of labels to sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sAipFsaobKM0",
    "outputId": "522c9093-00c9-4c75-deea-89685e39c13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 4 distinct labels in the corpus\n",
      "there are 5500 sentences in the corpus\n",
      "16\n",
      "['B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'I', 'O']\n",
      "[1, 2, 2, 2, 2, 2, 3, 3, 1, 2, 3, 3, 1, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import collections \n",
    "label2int = collections.defaultdict(lambda: len(label2int))\n",
    "label2int['<eos>'] = 0\n",
    "# convert the label sequences to sequences of integers\n",
    "int_labels = []\n",
    "for label in labels:\n",
    "    int_labels.append([label2int[token] for token in label])\n",
    "    \n",
    "print(\"there are \"+str(len(label2int))+ \" distinct labels in the corpus\")\n",
    "print(\"there are \"+str(len(int_labels))+\" sentences in the corpus\")\n",
    "\n",
    "print(str(len(int_labels[0])))\n",
    "print(labels[0])\n",
    "print(int_labels[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmX8f6yUbKM5"
   },
   "source": [
    "### Convert the tokens to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "fKajEtt-bKM9",
    "outputId": "579a7784-9126-418c-f3f0-6aac389d0e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 4596 distinct labels in the corpus\n",
      "there are 5500 sentences in the corpus\n",
      "['Man', 'with', 'long', 'blond-hair', 'and', 'a', 'plate', 'of', 'food', 'in', 'his', 'hands', '.']\n",
      "[16, 17, 18, 19, 20, 1, 21, 3, 22, 23, 24, 25, 15]\n",
      "['B', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O']\n",
      "[1, 3, 1, 2, 3, 1, 2, 2, 2, 3, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import collections \n",
    "token2int = collections.defaultdict(lambda: len(token2int))\n",
    "token2int['<eos>'] = 0\n",
    "#convert the texts to sequences of integers\n",
    "int_texts = []\n",
    "for text in texts:\n",
    "    int_texts.append([token2int[token.lower()] for token in text])\n",
    "    \n",
    "print(\"there are \"+str(len(token2int))+ \" distinct labels in the corpus\")\n",
    "print(\"there are \"+str(len(int_texts))+\" sentences in the corpus\")\n",
    "\n",
    "print(texts[1])\n",
    "print(int_texts[1])\n",
    "print(labels[1])\n",
    "print(int_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knZtpGzZbKND"
   },
   "source": [
    "### Create the reverse dictionaries (int2label, int2token) to map integer labels and integer tokens back to labels and tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAHF8M2YbKNF"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "int2label = {y: x for x, y in label2int.items()}\n",
    "int2token = {y: x for x, y in token2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgHjYS72bKNP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "max_len = 16\n",
    "batch_size = 64\n",
    "embed_size = 300\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1if0QX_NbKNW",
    "outputId": "adf5b54d-2c41-4a2f-9a65-c0e3790e420c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 16, 85, 86,  1, 87, 88, 36, 89,  1, 90, 15,  0,  0,  0,  0])\n",
      "tensor([1, 2, 3, 3, 1, 2, 2, 3, 3, 1, 2, 3, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X = torch.zeros(len(int_texts), max_len).long()\n",
    "Y = torch.zeros(len(int_labels), max_len).long()\n",
    "\n",
    "for i, (text,label) in enumerate(zip(int_texts, int_labels)):\n",
    "    length = min(max_len, len(text))\n",
    "    X[i,:length] = torch.LongTensor(text[:length])\n",
    "    Y[i,:length] = torch.LongTensor(label[:length])\n",
    "    \n",
    "print(X[12])\n",
    "print(Y[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMphuDEkbKNe"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train = X[:5000]\n",
    "Y_train = Y[:5000]\n",
    "X_valid = X[:5000]\n",
    "Y_valid = Y[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1duVtHubKNk"
   },
   "source": [
    "#### Use torch DataLoader to split training and validation data into batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEqf4ZwJbKNl"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "valid_set = TensorDataset(X_valid, Y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_9dJoanbKNp"
   },
   "source": [
    "## Using pre-trained Fasttext embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-jnSQ43tbKNy",
    "outputId": "a21242f6-daec-428f-8206-e67524890524"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0159,  0.2218, -0.0831,  0.3253, -0.0533,  0.1563,  0.3345,  0.0572,\n",
       "        -0.1407, -0.0389])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "pretrained_weights = torch.zeros(len(token2int), 300)\n",
    "with open('wiki.en.filtered.vec') as fp:\n",
    "    for line in fp:\n",
    "        tokens = line.strip().split()\n",
    "        if tokens[0] in token2int:\n",
    "            # map index in token2int to glove embedding of corresponding token\n",
    "            pretrained_weights[token2int[tokens[0]]] = torch.FloatTensor([float(x) for x in tokens[1:]])\n",
    "\n",
    "pretrained_weights[12][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, train and evaluate your neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "bbrhekbVbKN4",
    "outputId": "5fcdb589-e8f2-4a53-e113-541f9186a5cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(4596, 300, padding_idx=0)\n",
       "  (rnn): GRU(300, 128, bias=False, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (decision): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(token2int), embed_size, padding_idx=token2int ['<eos>'])\n",
    "        self.embed.weight = nn.Parameter(pretrained_weights, requires_grad=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, bias=False, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.decision = nn.Linear(hidden_size * 1 * 1, len(label2int))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        output, hidden = self.rnn(embed)\n",
    "        return self.decision(self.dropout(output))\n",
    "\n",
    "rnn_model = RNN()\n",
    "rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OBk-ExhZmqPj",
    "outputId": "12eadb42-6d23-4320-d758-f9aa5120b087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "# Checking the size (batch_size, sequence_length, num_labels) of the output\n",
    "\n",
    "with torch.no_grad():\n",
    "  print(rnn_model(X[:2]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bc_mfttznImx",
    "outputId": "67ea45dd-650c-4ee7-a19a-4adcf6cd1988"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02180137758255005, 0.3628871889499991)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perf(model, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_loss = correct = num_loss = num_perf = 0\n",
    "    for x, y in loader:\n",
    "      with torch.no_grad():\n",
    "        y_scores = model(x)\n",
    "        loss = criterion(y_scores.view(y.size(0) * y.size(1), -1), y.view(y.size(0) * y.size(1)))\n",
    "        y_pred = torch.max(y_scores, 2)[1]\n",
    "        mask = (y != 0)\n",
    "        correct += torch.sum((y_pred.data == y) * mask)\n",
    "        total_loss += loss.item()\n",
    "        num_loss += len(y)\n",
    "        num_perf += torch.sum(mask).item()\n",
    "    return total_loss / num_loss, correct.item() / num_perf\n",
    "\n",
    "perf(rnn_model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbPWKZO2bKOJ"
   },
   "source": [
    "#### Define the training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "u3-5f5vLnTv3",
    "outputId": "e37108b0-ca96-493d-b337-d9416493c06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.008177814197540283 0.002274954153597355 0.931044984682635\n",
      "1 0.0015918059520423412 0.0011125849187374115 0.9697056557802899\n",
      "2 0.0010381606325507164 0.0008231632005423307 0.9770329099410595\n",
      "3 0.0008425289627164602 0.0007026651084423066 0.9807234095917161\n",
      "4 0.0007496314894407987 0.0006334372773766517 0.9826761496981314\n",
      "5 0.0006813538726419211 0.0005893108481541276 0.9839302029774808\n",
      "6 0.0006317454492673278 0.0005267989452928304 0.9853275766316129\n",
      "7 0.0005821802375838161 0.0005016943197697401 0.9863845643956359\n",
      "8 0.0005378525465726852 0.00045420381259173156 0.9875311273938981\n",
      "9 0.0004940528498962521 0.0003972992794588208 0.9897525932030312\n"
     ]
    }
   ],
   "source": [
    "def fit(model, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # add gradients to all parameters (required by pytorch for training)\n",
    "    optimizer = optim.Adam(filter(lambda param: param.requires_grad, model.parameters()))\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_scores = model(x)\n",
    "            loss = criterion(y_scores.view(y.size(0) * y.size(1), -1), y.view(y.size(0) * y.size(1)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num += len(y)\n",
    "        print(epoch, total_loss / num, *perf(model, valid_loader))\n",
    "\n",
    "rnn_model = RNN()\n",
    "fit(rnn_model, 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05_tagging-crf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
